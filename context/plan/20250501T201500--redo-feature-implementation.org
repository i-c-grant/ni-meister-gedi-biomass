#+title:      Redo Feature Implementation Plan
#+date:       [2025-05-01 Thu 20:15]
#+filetags:   :nimeistergedibiomassglobal:project:implementation:
#+identifier: 20250501T201500

* Implementation Overview
** Objective
Add --redo option to run_on_maap.py to exclude previously successful granules from new runs

** Key Components
1. New CLI options: --redo and --force-redo
2. S3 output path construction logic
3. Granule ID extraction from output filenames
4. Existing output detection and exclusion
5. Safety checks for tag conflicts

* Dependencies
- MAAP API access
- boto3 S3 client configuration
- Existing filename/granule matching logic

* Step-by-Step Implementation Plan

** 1. Add New Command Line Options
#+begin_src python
@click.option("--redo", type=str, help="Tag of previous run to exclude")
@click.option("--force-redo", is_flag=True, help="Allow redo with same tag")
#+end_src

** 2. Filename Parsing Utilities
#+begin_src python
def get_key_from_output(filename: str) -> str:
    """Extract base key from output filename"""
    return filename.split(".")[0].strip()
#+end_src

** 3. S3 Output Querying
Note: the output files are named according to date of acquisition, time of acquisition, and sub-orbit granule number, as described [[https://lpdaac.usgs.gov/documents/590/GEDIL01_User_Guide_V1.pdf][in the L1B guide]].

#+begin_src python
def get_existing_outputs(username: str, algo_id: str, 
                         version: str, redo_tag: str) -> Set[str]:
    """Get set of processed output keys from previous run"""
    s3 = boto3.client('s3')
    existing = set()
    
    paginator = s3.get_paginator('list_objects_v2')
    for page in paginator.paginate(
        Bucket="maap-ops-workspace",
        Prefix=f"{username}/dps_output/{algo_id}/{version}/{redo_tag}/"
    ):
        for obj in page.get('Contents', []):
            if obj['Key'].endswith('.gpkg.bz2'):
                key = get_key_from_output(Path(obj['Key']).name)
                existing.add(key)
                
    return existing
#+end_src

** 4. Granule Filtering Integration
Modify main() workflow:
1. After granule matching (line ~280)
2. Before job submission (line ~325)
   
** 5. Safety Checks
#+begin_src python
if redo_tag:
    if not force_redo and redo_tag == tag:
        raise ValueError(f"Cannot redo with same tag '{tag}'")
    existing = get_existing_outputs(username, algo_id, algo_version, redo_tag)
    if not existing:
        raise ValueError(f"No valid outputs found for redo tag '{redo_tag}'")
#+end_src

